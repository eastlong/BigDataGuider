<!-- TOC -->

- [1. Hadoop安装](#1-hadoop安装)
    - [1.1. 准备工作](#11-准备工作)
        - [1.1.1. 网卡配置](#111-网卡配置)
        - [1.1.2. 修改主机名](#112-修改主机名)
        - [1.1.3. jdk安装](#113-jdk安装)
        - [1.1.4. 免密码登录配置](#114-免密码登录配置)
    - [1.2. 安装Hadoop](#12-安装hadoop)
- [2. Hadoop 运行模式](#2-hadoop-运行模式)
    - [2.1. 本地模式](#21-本地模式)

<!-- /TOC -->
# 1. Hadoop安装
## 1.1. 准备工作
* 集群规划：

| 主机名 | ip地址 | 操作系统 |
| :---: | :----: | :----: |
| hadoop101 | 192.168.193.101 | centos7 |
| hadoop102 | 192.168.193.102 | centos7 |
| hadoop103 | 192.168.193.103 | centos7 |

* hadoop版本：hadoop3.2.1

### 1.1.1. 网卡配置
对于Centos7而言，网卡配置需要注意一下几点：
1. 由于虚拟机克隆拷贝过程会对网卡造成一定的影响，所以必须做一些修改：
```sh
# 查看网卡
$ ifconfig
```
一般而言：会有两个网卡：`ens32`和`lo`。
```sh
$ cd /etc/sysconfig/network-scripts/

$ sudo vim ifcfg-eno16777736

# 将DEVICE与NAME修改为与ifconfig出现的网卡名相同
DEVICE=ens32
NAME=ens32
```
2. 静态网卡配置  
```sh
$ sudo vim ifcfg-eno16777736

# 需要修改的地方如下
BOOTPROTO=static  # 将原来的dhcp修改为static

# 配置静态网卡
IPADDR=192.168.193.101
NETMASK=255.255.255.0
GATEWAY=192.168.193.2 
# 注意：网关的配置请查看 vim /etc/resolv.conf 

# 必不可少的DNS配置
DNS1=114.114.114.114
DNS2=8.8.8.8
```

3.重启网卡
```sh
systemctl restart network

# 重启系统
reboot
```

<div STYLE="page-break-after: always;"></div>

### 1.1.2. 修改主机名
1. 修改主机名为hadoop101  
```sh
$ hostnamectl set-hostname hadoop101

$ logout # 重新登录
```

2. 添加域名映射  
```sh
$ sudo vim /etc/hosts

# 添加：
192.168.193.101  hadoop101
192.168.193.102  hadoop102
192.168.193.103  hadoop103
```

3. 在windows系统中修该配置文件：
```
C:\Windows\System32\drivers\etc\hosts
# 添加域名：
192.168.193.101  hadoop101
192.168.193.102  hadoop102
192.168.193.103  hadoop103
```

### 1.1.3. jdk安装
1.解压安装
```sh
$ tar -zxvf jdk-8u40-linux-x64.tar.gz 
$ mv jdk1.8.0_40 jdk

```
2.环境变量配置
```
sudo vim /etc/profile

export JAVA_HOME=/home/hadoop/app/jdk
export PATH=$PATH:$JAVA_HOME/bin

$ source /etc/profile
```

### 1.1.4. 免密码登录配置
```sh
$ ssh-keygen
$ cd .ssh
$ ls
id_rsa  id_rsa.pub
$ cat id_rsa.pub >> authorized_keys

# 若原先生成过秘钥，可以删除.ssh文件夹重新操作
赋权限：
chmod 600 authorized_keys

ssh localhost  #验证是否操作成功
可以直接登录到localhost
hadoop@hadoop1:~/.ssh$ ls
authorized_keys  id_rsa  id_rsa.pub  
#### 拷贝到其他主机
scp -r .ssh hadoop@hadoop102:/home/hadoop
scp -r .ssh hadoop@hadoop103:/home/hadoop

```

## 1.2. 安装Hadoop
1.hadoop下载地址  
[1.hadoop官网下载](https://archive.apache.org/dist/hadoop/common/)  
[2.清华镜像源下载](https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/)

2.解压缩
```sh
tar -zxvf hadoop-3.2.1.tar.gz -C /home/hadoop/app

mv hadoop-3.2.1 hadoop
```


3.环境变量配置
```sh
$ sudo vi /etc/profile

## 添加如下内容
##HADOOP_HOME
export HADOOP_HOME=/home/hadoop/app/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

## 让修改后的文件生效：
$ source /etc/profile
```

4.测试是否安装成功
```sh
$ hadoop version
```

5.分发hadoop安装文件到hadoop102和hadoop103主机上。
```sh
$ scp -r app/hadoop hadoop@hadoop102:/home/hadoop/app

$ scp -r app/hadoop hadoop@hadoop103:/home/hadoop/app
```


# 2. Hadoop 运行模式
Hadoop 运行模式包括：本地模式、伪分布式模式以及完全分布式模式。

## 2.1. 本地模式
上述步骤安装后即本地模式：
* WordCount案例：
1.要创建 HADOOP_HOME/files/wcfile.txt
```
hello hadoop
hello hive
hello spark
hello zookeeper
```

$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar  wordcount files/wcfile.txt wcoutput/

