# Spark安装
## Spark安装模式
1.Spark通常有本地模式、Standalone模式、Yarn安装模式等。

## Spark安装步骤

```sh
$ pwd
/home/hadoop/app

$ tar -zxvf spark-2.4.3-bin-hadoop2.6.tgz 

$ mv spark-2.4.3-bin-hadoop2.6 spark


```

## 官方求Pie的案例
```sh
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--executor-memory 1G \
--total-executor-cores 2 \
./examples/jars/spark-examples_2.11-2.4.3.jar \
100
```
### 提交代码命令
```sh
bin/spark-submit \
--class <main-class>
--master <master-url> \
--deploy-mode <deploy-mode> \
--conf <key>=<value> \
... 
<application-jar> \
[application-arguments]
```

### 参数说明
* --class: 你的应用的启动类
* --master: 指定 Master 的地址，默认为 Local;  
* --deploy-mode: 部署模式：client、yarn等 (default: client)
* -- application-arguments: 传给 main()方法的参数
* --executor-memory 1G 指定每个 executor 可用内存为 1G
* --total-executor-cores 2 指定每个 executor 使用的 cup 核数为 2 个
